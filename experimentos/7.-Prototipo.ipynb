{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"jumbotron\">\n",
    "  <h1><i class=\"fa fa-bar-chart\" aria-hidden=\"true\"></i>Clase prototipo</h1>\n",
    "  <p></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El prototipo es una clase en código python con el modelo seleccionado del notebook 5.\n",
    "El cual incluye los métodos para \n",
    "\n",
    "- Lectura de los datos de entrenamiento (csv)\n",
    "- Validar datos y definir variables de clase (target, nombre de features, ...)\n",
    "- Preprocesar los datos de entrenamiento(segun el notebook 4)\n",
    "- Almacenar modelos de pre procesamiento (z-score , label coding , one hot coding)\n",
    "- Leer los modelos de pre procesamientO \n",
    "- Preprocesar datos para nuevos casos (productivo)\n",
    "- Entrar modelo modelo(segun el notebook 5)\n",
    "- Guardar modelo en formato pickle\n",
    "- Cargar el modelo entrenado\n",
    "- run : funciones pricipal el cual es el pipeline del proceso completo(load, pre procesado, entraniento,...)\n",
    "- Predicir nuevos casos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.py         \u001b[34mcategorizador\u001b[m\u001b[m/ \u001b[34mdata\u001b[m\u001b[m/          \u001b[34mexperimentos\u001b[m\u001b[m/  \u001b[34mmodel\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile categorizador/classifier.py\n",
    "\n",
    "\n",
    "from pandas import read_csv,concat\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas import DataFrame\n",
    "from numpy import where, number\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from joblib import dump, load\n",
    "\n",
    "# Función para el tratamiento de outliers por cuartiles y desviación estándar\n",
    "def treat_outliers(data, numeric_columns, factor=1.5):\n",
    "    treated_data = data.copy()\n",
    "    for column in numeric_columns:\n",
    "        q1 = data[column].quantile(0.25)\n",
    "        q3 = data[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - factor * iqr\n",
    "        upper_bound = q3 + factor * iqr\n",
    "        treated_data[column] = where(treated_data[column] < lower_bound, lower_bound, treated_data[column])\n",
    "        treated_data[column] = where(treated_data[column] > upper_bound, upper_bound, treated_data[column])\n",
    "    return treated_data\n",
    "\n",
    "class Classifier:\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    Clase para procesar datos, entrenar un modelo de RandomForest y realizar predicciones.\n",
    "\n",
    "    Métodos\n",
    "    -------\n",
    "    preprocess_data():\n",
    "        Método para preprocesar datos. (Personalizar según necesidad)\n",
    "\n",
    "    transform_data():\n",
    "        Método para transformar los datos (imputación, escalado, codificación, etc.)\n",
    "\n",
    "    split_data():\n",
    "        Divide los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "    train_model(X_train, y_train):\n",
    "        Entrena el modelo RandomForest con los datos de entrenamiento.\n",
    "\n",
    "    evaluate_model(X_test, y_test):\n",
    "        Evalúa el modelo en los datos de prueba y devuelve la precisión.\n",
    "\n",
    "    save_model(filename):\n",
    "        Guarda el modelo entrenado y los objetos de preprocesamiento en archivos.\n",
    "\n",
    "    load_model(filename):\n",
    "        Carga el modelo y los objetos de preprocesamiento desde archivos.\n",
    "\n",
    "    retrain_model(new_data_path):\n",
    "        Reentrena el modelo con nuevos datos.\n",
    "\n",
    "    treat_outliers(data, numeric_columns, factor=1.5):\n",
    "        Trata los outliers en las columnas numéricas.\n",
    "\n",
    "    transform_for_prediction(X):\n",
    "        Transforma los datos nuevos para predicción utilizando los mismos pasos de preprocesamiento.\n",
    "\n",
    "    predict(new_data):\n",
    "        Realiza predicciones sobre nuevos datos.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Inicializa la clase Classifier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path : str, optional\n",
    "            Ruta al archivo CSV que contiene los datos. Si no se proporciona, se debe cargar manualmente.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        # Convertir las columnas a su dtype correcto \n",
    "        self.numeric_columns = ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "        self.categorical_columns = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "        self.label = ['Survived']\n",
    "\n",
    "        self.columns = ['PassengerId', \n",
    "                        'Pclass',\n",
    "                        'Name', \n",
    "                        'Sex',\n",
    "                        'Age',\n",
    "                        'SibSp', \n",
    "                        'Parch',\n",
    "                        'Ticket', \n",
    "                        'Fare',\n",
    "                        'Cabin', \n",
    "                        'Embarked']\n",
    "\n",
    "        self.class_dict = {0: 'No sobrebvivio', 1: 'Sobrevivio'}\n",
    "        \n",
    "    def loader(self, data_path):\n",
    "\n",
    "        self.data = read_csv(data_path)\n",
    "        self.numeric_imputer = SimpleImputer(strategy='mean')\n",
    "        self.categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        self.data = treat_outliers(self.data, self.numeric_columns)\n",
    "    \n",
    "    def transform_data(self):\n",
    "\n",
    "        # Imputar datos faltantes\n",
    "        self.data[self.numeric_columns] = self.numeric_imputer.fit_transform(self.data[self.numeric_columns])\n",
    "        self.data[self.categorical_columns] = self.categorical_imputer.fit_transform(self.data[self.categorical_columns])\n",
    "        \n",
    "        # Escalar características numéricas\n",
    "        self.data[self.numeric_columns] = self.scaler.fit_transform(self.data[self.numeric_columns])\n",
    "        \n",
    "        # Codificar características categóricas\n",
    "        encoded_categories = self.encoder.fit_transform(self.data[self.categorical_columns]).toarray()\n",
    "        encoded_df = DataFrame(encoded_categories, columns=self.encoder.get_feature_names_out(self.categorical_columns))\n",
    "        \n",
    "        \n",
    "        numeric_columns_extend = self.numeric_columns + ['Survived']\n",
    "        # Concatenar datos transformados\n",
    "        self.data = concat([self.data[numeric_columns_extend], encoded_df], axis=1)\n",
    "\n",
    "    \n",
    "    def split_data(self):\n",
    "        X = self.data.drop(columns=['Survived'])\n",
    "        y = self.data['Survived']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.model = RandomForestClassifier()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return accuracy\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        \n",
    "        filename = 'model/' + filename\n",
    "        \n",
    "        dump(self.model, filename)\n",
    "        \n",
    "        dump(self.numeric_imputer, filename + '_numeric_imputer.joblib')\n",
    "        dump(self.categorical_imputer, filename + '_categorical_imputer.joblib')\n",
    "        dump(self.scaler, filename + '_scaler.joblib')\n",
    "        dump(self.encoder, filename + '_encoder.joblib')\n",
    "    \n",
    "    def load_model(self, filename):\n",
    "        self.model = load(filename)\n",
    "        self.numeric_imputer = load(filename + '_numeric_imputer.joblib')\n",
    "        self.categorical_imputer = load(filename + '_categorical_imputer.joblib')\n",
    "        self.scaler = load(filename + '_scaler.joblib')\n",
    "        self.encoder = load(filename + '_encoder.joblib')\n",
    "    \n",
    "    def transform_for_prediction(self, X):\n",
    "        # Tratamiento de outliers\n",
    "        X = treat_outliers(X, self.numeric_columns)\n",
    "        \n",
    "        # Imputar valores faltantes\n",
    "        X[self.numeric_columns] = self.numeric_imputer.transform(X[self.numeric_columns])\n",
    "        X[self.categorical_columns] = self.categorical_imputer.transform(X[self.categorical_columns])\n",
    "\n",
    "        # Escalar características numéricas\n",
    "        X[self.numeric_columns] = self.scaler.transform(X[self.numeric_columns])\n",
    "\n",
    "        # One-Hot Encoding para características categóricas\n",
    "        encoded_cats = self.encoder.transform(X[self.categorical_columns]).toarray()\n",
    "        encoded_cat_df = DataFrame(encoded_cats, columns=self.encoder.get_feature_names_out(self.categorical_columns))\n",
    "        \n",
    "        X = X.drop(columns=self.categorical_columns).reset_index(drop=True)\n",
    "        X = concat([X, encoded_cat_df], axis=1)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def predict(self, new_data):\n",
    "\n",
    "        \n",
    "        # Asegurarse de que los nuevos datos sean un DataFrame de pandas\n",
    "        if not isinstance(new_data, DataFrame):\n",
    "            new_data = DataFrame(new_data, columns= self.columns)\n",
    "        \n",
    "        # Transformar los datos nuevos para predicción\n",
    "        X_new = self.transform_for_prediction(new_data)\n",
    "        \n",
    "        # Hacer predicciones\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        \"\"\"\n",
    "        predictions_proba = self.model.predict_proba(X_new)\n",
    "        predicts_ = []\n",
    "        for prediction in predictions:\n",
    "            predicts_.append(self.class_dict[prediction])\n",
    "\n",
    "        \"\"\"\n",
    "            \n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Uso\n",
    "- Entrenamiento y guardado del modelo:\n",
    "  ```python\n",
    "  data_processor = DataProcessor()\n",
    "  data_processor.loader('titanic.csv')\n",
    "  data_processor.preprocess_data()\n",
    "  data_processor.transform_data()\n",
    "  X_train, X_test, y_train, y_test = data_processor.split_data()\n",
    "  data_processor.train_model(X_train, y_train)\n",
    "  data_processor.save_model('trained_model.joblib')\n",
    "  ```\n",
    "\n",
    "- Cargar el modelo y hacer predicciones con nuevos datos:\n",
    "  ```python\n",
    "  data_processor.load_model('trained_model.joblib')\n",
    "  new_data = pd.read_csv('new_titanic_data.csv')\n",
    "  predictions = data_processor.predict(new_data)\n",
    "  print(predictions)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.py        \u001b[34mcategorizador\u001b[m\u001b[m \u001b[34mdata\u001b[m\u001b[m          \u001b[34mexperimentos\u001b[m\u001b[m  \u001b[34mmodel\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "path= 'data/raw/titanic.csv'\n",
    "\n",
    "# Ejemplo de uso\n",
    "data_processor = Classifier()\n",
    "data_processor.loader(path)\n",
    "data_processor.preprocess_data()\n",
    "data_processor.transform_data()\n",
    "X_train, X_test, y_train, y_test = data_processor.split_data()\n",
    "data_processor.train_model(X_train, y_train)\n",
    "# Suponiendo que tienes nuevos datos en un archivo llamado 'nuevos_datos.csv'\n",
    "accuracy = data_processor.evaluate_model(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "salida  = data_processor.save_model('titanic_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.py        \u001b[34mcategorizador\u001b[m\u001b[m \u001b[34mdata\u001b[m\u001b[m          \u001b[34mexperimentos\u001b[m\u001b[m  \u001b[34mmodel\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= 'data/raw/titanic.csv'\n",
    "\n",
    "data_processor = Classifier()\n",
    "data_processor.load_model('model/titanic_model')\n",
    "new_data = read_csv(path)\n",
    "del new_data['Survived']\n",
    "data_processor.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_dato = new_data.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "5            6       3                                   Moran, Mr. James   \n",
       "6            7       1                            McCarthy, Mr. Timothy J   \n",
       "7            8       3                     Palsson, Master. Gosta Leonard   \n",
       "8            9       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9           10       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  \n",
       "5    male   NaN      0      0            330877   8.4583   NaN        Q  \n",
       "6    male  54.0      0      0             17463  51.8625   E46        S  \n",
       "7    male   2.0      3      1            349909  21.0750   NaN        S  \n",
       "8  female  27.0      0      2            347742  11.1333   NaN        S  \n",
       "9  female  14.0      1      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevo_dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = Classifier()\n",
    "data_processor.load_model('model/titanic_model')\n",
    "\n",
    "predictions = data_processor.predict(nuevo_dato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array  = nuevo_dato.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processor = Classifier()\n",
    "data_processor.load_model('model/titanic_model')\n",
    "data_processor.predict(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡¡¡ cuando es numpy.ndarray te cuidado con el orden de los datos !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting api.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile api.py\n",
    "from flask import Flask, jsonify, request\n",
    "from jsonschema import validate\n",
    "from pandas import DataFrame\n",
    "# Importa la clase Classifier de tu módulo\n",
    "from categorizador.classifier import Classifier\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Cargar la instancia de Classifier con el modelo entrenado\n",
    "data_processor = Classifier()\n",
    "data_processor.load_model('model/titanic_model')\n",
    "\n",
    "# Esquema JSON para validar las entradas\n",
    "input_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"PassengerId\": {\"type\": \"number\"},\n",
    "        \"Pclass\": {\"type\": \"number\"},\n",
    "        \"Name\": {\"type\": \"string\"},\n",
    "        \"Sex\": {\"type\": \"string\"},\n",
    "        \"Age\": {\"type\": \"number\"},\n",
    "        \"SibSp\": {\"type\": \"number\"},\n",
    "        \"Parch\": {\"type\": \"number\"},\n",
    "        \"Ticket\": {\"type\": \"string\"},\n",
    "        \"Fare\": {\"type\": \"number\"},\n",
    "        \"Cabin\": {\"type\": \"string\"},\n",
    "        \"Embarked\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"PassengerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "}\n",
    "\n",
    "# Ruta para realizar predicciones\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Obtener los datos de form-data de la solicitud\n",
    "    features = {\n",
    "        \"PassengerId\": int(request.form['PassengerId']),\n",
    "        \"Pclass\": int(request.form['Pclass']),\n",
    "        \"Name\": request.form['Name'],\n",
    "        \"Sex\": request.form['Sex'],\n",
    "        \"Age\": float(request.form['Age']),\n",
    "        \"SibSp\": int(request.form['SibSp']),\n",
    "        \"Parch\": int(request.form['Parch']),\n",
    "        \"Ticket\": request.form['Ticket'],\n",
    "        \"Fare\": float(request.form['Fare']),\n",
    "        \"Cabin\": request.form['Cabin'],\n",
    "        \"Embarked\": request.form['Embarked']\n",
    "    }\n",
    "\n",
    "    # Validar las entradas con el esquema definido\n",
    "    try:\n",
    "        validate(instance=features, schema=input_schema)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "    # Crear un DataFrame a partir de los datos recibidos\n",
    "    df = DataFrame([features])\n",
    "\n",
    "    # Realizar la predicción con el modelo cargado\n",
    "    predictions = data_processor.predict(df)\n",
    "    \n",
    "    print(predictions)\n",
    "    # Devolver la respuesta en formato JSON\n",
    "    return jsonify({\"response\": predictions.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "curl -X POST -F \"PassengerId=123\" \\\n",
    "-F \"Pclass=1\" \\\n",
    "-F \"Name=John Doe\" \\\n",
    "-F \"Sex=male\" \\\n",
    "-F \"Age=30\" \\\n",
    "-F \"SibSp=0\" \\\n",
    "-F \"Parch=0\" \\\n",
    "-F \"Ticket=12345\" \\\n",
    "-F \"Fare=50.5\" \\\n",
    "-F \"Cabin=C123\" \\\n",
    "-F \"Embarked=S\" \\\n",
    "http://localhost:8080/predict\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
